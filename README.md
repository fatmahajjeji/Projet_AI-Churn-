# ğŸ“Š Customer Churn Prediction â€“ Machine Learning Project

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **A complete end-to-end Machine Learning pipeline for predicting customer churn in the telecom industry, with emphasis on interpretability, reproducibility, and business value.**

---

## ğŸ” Project Overview

This project focuses on predicting customer churn (whether a client will leave a telecom company) using supervised Machine Learning techniques. The goal is to build a **robust, interpretable and well-validated ML pipeline**, from raw data preprocessing to final model evaluation.

The project was developed using **Python** and **scikit-learn**, following best practices to avoid data leakage and ensure reproducibility.

### ğŸ¯ Key Objectives

- âœ… Master core Machine Learning techniques
- âœ… Apply end-to-end ML pipeline using scikit-learn
- âœ… Justify every preprocessing decision
- âœ… Compare multiple ML models fairly
- âœ… Interpret results from both technical and business perspectives

---

## ğŸ“‚ Dataset Description

| Property | Value |
|----------|-------|
| **Name** | Telco Customer Churn |
| **Source** | [Kaggle](https://www.kaggle.com/) |
| **Size** | 7,043 rows Ã— 21 columns |
| **Type** | Supervised Learning â€“ Binary Classification |
| **Target** | `Churn` (Yes / No) |
| **Class Balance** | ~26.5% churners (imbalanced) |

### ğŸ“Œ Feature Types

**Numerical Features:**
- `tenure` â€“ Number of months with the company
- `MonthlyCharges` â€“ Monthly service cost
- `TotalCharges` â€“ Total amount charged

**Categorical Features:**
- `Gender`, `Contract`, `InternetService`, `PaymentMethod`, etc.

âš ï¸ **Note:** The dataset is imbalanced (~26.5% churners), which is handled explicitly during modeling.

---

## ğŸ§¹ Data Preprocessing

All preprocessing steps are **fully justified** and documented in the notebook.

### âœ” Missing Values Handling

| Issue | Solution | Justification |
|-------|----------|---------------|
| `TotalCharges` as object | Converted to numeric | Data type correction |
| Missing values in `TotalCharges` | Imputed with `0` | Corresponds to new customers (`tenure = 0`) |

### âœ” Outlier Analysis

- **Detection Method:** IQR (Interquartile Range)
- **Finding:** Outliers correspond to high-value / long-tenure customers
- **Decision:** âŒ No removal (to avoid business bias)
- **Solution:** âœ… `RobustScaler` for robustness

### âœ” Encoding & Scaling

**Numerical Features:**
- `RobustScaler` â€“ Resilient to outliers

**Categorical Features:**
- `OneHotEncoder` with:
  - `drop='first'` â†’ Avoids multicollinearity
  - `handle_unknown='ignore'` â†’ Production-safe

### âœ” Data Leakage Prevention

All preprocessing steps applied using **scikit-learn Pipelines**:
- `fit()` only on training data
- `transform()` on both train and test sets

---

## âš™ï¸ Feature Selection

### Challenge
- OneHotEncoding resulted in **5,663 features**
- Risk of **overfitting**

### Solution
```python
SelectKBest(score_func=f_classif, k=30)
```
- **Method:** ANOVA F-test
- **Result:** Reduced to **30 most informative features**

---

## ğŸ¤– Machine Learning Models

Seven different models were trained and compared:

| Model | Type |
|-------|------|
| **Logistic Regression** | Linear Model |
| **Random Forest** | Ensemble (Bagging) |
| **XGBoost** | Ensemble (Boosting) |
| **Support Vector Machine (SVC)** | Kernel-based |
| **K-Nearest Neighbors (KNN)** | Instance-based |
| **Decision Tree** | Tree-based |
| **Naive Bayes** | Probabilistic |

### âš–ï¸ Model Optimization

- **Validation Strategy:** 5-Fold Cross Validation
- **Metrics Evaluated:**
  - Accuracy
  - Precision
  - Recall
  - F1-score
  - ROC-AUC
- **Class Imbalance Handling:** `class_weight='balanced'` applied when relevant

---

## ğŸ“ˆ Results

### ğŸ† Best Model: Logistic Regression

| Metric | Score |
|--------|-------|
| **F1-score** | â‰ˆ 0.61 |
| **ROC-AUC** | â‰ˆ 0.78 |
| **Accuracy** | â‰ˆ 82% |

#### ğŸ“Œ Why Logistic Regression?

âœ… Strong balance between precision and recall  
âœ… High interpretability (coefficient analysis)  
âœ… Stability on unseen data  
âœ… Fast inference time  

---

## ğŸ“Š Visualizations

The project includes comprehensive visualizations:

- ğŸ“‰ Churn distribution analysis
- ğŸ“Š Model performance comparison
- ğŸ¯ Confusion matrix heatmap
- ğŸ–¼ï¸ LinkedIn-style professional infographic

### ğŸ“· Project Showcase

![Project Infographic](project_showcase_ai.png)

---

## ğŸ’¡ Business Insights

### Key Outcomes

| Impact | Description |
|--------|-------------|
| âœ… **Improved Detection** | 53% better identification of at-risk customers |
| âœ… **Reduced False Alerts** | 42% fewer false churn predictions |
| âœ… **Better Targeting** | Precise customer retention campaigns |
| âœ… **Clear Trade-offs** | Balanced precision-recall for business needs |

### ROI Estimation
- **Potential ROI:** +25%
- **Analysis Time Reduction:** -60%

---

## ğŸ›  Technologies Used

### Core Libraries
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)

### Visualization & ML
- **Matplotlib** â€“ Static visualizations
- **Seaborn** â€“ Statistical plots
- **XGBoost** â€“ Gradient boosting
- **Google Colab / Jupyter** â€“ Interactive development

---

## â–¶ï¸ How to Run the Project

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/customer-churn-prediction.git
cd customer-churn-prediction
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Launch Jupyter Notebook
```bash
jupyter notebook
```

### 4. Open the Main Notebook
Navigate to `Customer_Churn_Prediction.ipynb` and run all cells.

---

## ğŸ“ Project Structure

```
customer-churn-prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ telco_customer_churn.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Customer_Churn_Prediction.ipynb
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ linkedin_project_showcase_ai.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸ“Œ Author

**Fatma Hajjeji**

ğŸ“§ Email: [fatmahajjeji9@gmail.com](mailto:fatmahajjeji9@gmail.com)  
ğŸ”— LinkedIn: [linkedin.com/in/fatma-hajjeji-29b1a8295](https://www.linkedin.com/in/fatma-hajjeji-29b1a8295)  
ğŸ’» GitHub: [github.com/yourusername](https://github.com/yourusername)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## â­ Conclusion

This project demonstrates a **complete and professional Machine Learning workflow**, combining:

- ğŸ”¬ Strong technical foundations
- ğŸ“Š Rigorous validation methodology
- ğŸ’¼ Clear business interpretation
- ğŸ“š Comprehensive documentation

It reflects my ability to design, evaluate, and explain ML solutions in a **real-world context**, making data-driven decisions that create tangible business value.

---

### ğŸ™ Acknowledgments

- Dataset provided by [Kaggle](https://www.kaggle.com/)
- Inspired by industry best practices in ML engineering

---

**â­ If you find this project useful, please consider giving it a star!**
